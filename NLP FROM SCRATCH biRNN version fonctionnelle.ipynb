{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0136d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from mosestokenizer import *\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc536e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1d2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5644b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f334a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0051322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "forme :  ['va !', 'go .']\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['j ai sommeil alors je pars maintenant .', 'i m sleepy so i am leaving now .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"forme : \",pairs[0])\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14b7b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tarekbenaissa/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/tarekbenaissa/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <681C00E9-5647-3069-B4FB-5DBB8737D1E1> /Users/tarekbenaissa/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <479B05C1-363C-3799-AAF4-CF79A0358897> /Users/tarekbenaissa/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/lib/libc10.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d8498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a0407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5687acbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice = 'cpu'\\nsource_vocab_size = 5000 ; # nombre de mots dans la phrase!! #dans le dataset\\nembedding_dim = 128\\nhidden_dim = 1000\\ntest_encoder = EncoderRNN( embedding_dim, hidden_dim)\\n\\na = torch.zeros((32, 5))\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "device = 'cpu'\n",
    "source_vocab_size = 5000 ; # nombre de mots dans la phrase!! #dans le dataset\n",
    "embedding_dim = 128\n",
    "hidden_dim = 1000\n",
    "test_encoder = EncoderRNN( embedding_dim, hidden_dim)\n",
    "\n",
    "a = torch.zeros((32, 5))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1547f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_seq, hid = test_encoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b1d3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass EncoderRNN(nn.Module):\\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\\n        super(EncoderRNN, self).__init__()\\n\\n        self.embedding = nn.Embedding(input_dim, emb_dim)\\n\\n        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\\n\\n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\\n        \\n        self.dropout = nn.Dropout(dropout)\\n        \\n        self.hidden_size = enc_hid_dim\\n    def forward(self, src):\\n\\n        # src= [src len, batch size]\\n\\n        embedded = self.dropout(self.embedding(src).view(1, 1, -1))\\n\\n        # embedded = [src len, batch size, emb dim]\\n\\n        output, hidden = self.rnn(embedded)\\n        output = output.reshape((2,1,self.hidden_size))\\n        \\n        print(\"output.size = \", output.size())\\n\\n        # outputs = [src len, batch size, hid dim * num directions]\\n        # hidden = [n layers * num directions, batch size, hid dim]\\n\\n        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\\n        # outputs are always from the last layer\\n\\n        # hidden [-2, :, : ] is the last of the forwards RNN\\n        # hidden [-1, :, : ] is the last of the backwards RNN\\n\\n        # 初始译码器隐藏是向前和向后的最终隐藏状态\\n        # 编码器RNNs通过一个线性层\\n       \\n        hidden = torch.tanh((torch.cat((hidden[0,:, :], hidden[1,:, :]), dim =1)))\\n        print(\"hidden size : \",hidden.size())\\n        #hidden = torch.tanh(hidden)\\n\\n        # outputs = [src len, batch size, enc hid dim * 2]\\n        # hidden = [batch size, dec hid dim]\\n        print(output.size())\\n        return output, hidden\\n    def initHidden(self):\\n        return torch.zeros(1, 1, self.hidden_size*2, dtype=torch.int32, device=device)\\n        \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.hidden_size = enc_hid_dim\n",
    "    def forward(self, src):\n",
    "\n",
    "        # src= [src len, batch size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src).view(1, 1, -1))\n",
    "\n",
    "        # embedded = [src len, batch size, emb dim]\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        output = output.reshape((2,1,self.hidden_size))\n",
    "        \n",
    "        print(\"output.size = \", output.size())\n",
    "\n",
    "        # outputs = [src len, batch size, hid dim * num directions]\n",
    "        # hidden = [n layers * num directions, batch size, hid dim]\n",
    "\n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        # outputs are always from the last layer\n",
    "\n",
    "        # hidden [-2, :, : ] is the last of the forwards RNN\n",
    "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
    "\n",
    "        # 初始译码器隐藏是向前和向后的最终隐藏状态\n",
    "        # 编码器RNNs通过一个线性层\n",
    "       \n",
    "        hidden = torch.tanh((torch.cat((hidden[0,:, :], hidden[1,:, :]), dim =1)))\n",
    "        print(\"hidden size : \",hidden.size())\n",
    "        #hidden = torch.tanh(hidden)\n",
    "\n",
    "        # outputs = [src len, batch size, enc hid dim * 2]\n",
    "        # hidden = [batch size, dec hid dim]\n",
    "        print(output.size())\n",
    "        return output, hidden\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size*2, dtype=torch.int32, device=device)\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d9dc5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # input_size : taille du vocabulaire français\n",
    "        # hidden\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,bidirectional=True)\n",
    "        \n",
    "        #self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n",
    "        #self.fc_output = nn.Linear(hidden_size*2, hidden_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output)\n",
    "        #print(\"hidden avant reshape : \",hidden.size())\n",
    "        #print(\"output avant reshape : \",output.size())\n",
    "        #print(\"output 512 : \", output)\n",
    "        \n",
    "        # output : nous donne la sortie des cellule de notre réseau RNN donc les yi --> c des code = token\n",
    "        # dimension : [lenth of sequence, batch size, 2*hidden_size] : quand c bidirectionnel\n",
    "        \n",
    "        # hidden : contient le dernier état de la mémoire de chaque cellule du RNN\n",
    "        # dimension : [2*number of layers, hidden_size]\n",
    "        \n",
    "        hidden = hidden.reshape((1,1,2*self.hidden_size))\n",
    "        #hidden = self.fc_hidden(hidden)\n",
    "        #output = self.fc_output(output)\n",
    "        #print(\"output 256 : \", output)\n",
    "        #print(\"hidden apres reshape : \",hidden.size())\n",
    "        #print(\"output apres reshape : \",encoder_states.size())\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, dtype=torch.int32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "9dc12d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*3 , self.max_length)  #max_length) \n",
    "        self.attn_combine = nn.Linear(self.hidden_size *3, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size*2, self.hidden_size*2)\n",
    "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        #print(\"-----------------------------\")\n",
    "        #print(\"hidden donné au decodeur size : \",input.size())\n",
    "        #print(\"logique psq on passe mot par mot\")\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        #print(\"size embedded donner par l encodeur : \", embedded[0].size())\n",
    "        #print(\"size hidden donner par l encodeur : \", hidden[0].size())\n",
    "        #print(\"size en entree de l attention : \", (torch.cat((embedded[0], hidden[0]), 1)).size())\n",
    "        #print(\"self.attn(torch.cat((embedded[0], hidden[0]), 1)) : \", self.attn(torch.cat((embedded[0], hidden[0]), 1)).size())\n",
    "        #print(\"attn_weights size : \", attn_weights.size())\n",
    "        #print(\"attn_weights.unsqueeze(0) size : \", attn_weights.unsqueeze(0).size())\n",
    "        #print(\"encoder_outputs.unsqueeze(0) size : \", encoder_outputs.unsqueeze(0).size())\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        #print(\" context vector attn_applied sortie du bmm : \", attn_applied.size())\n",
    "        \n",
    "        #output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        #print(\"context vector : \", output.size())\n",
    "        #output = self.attn_combine(output).unsqueeze(0)\n",
    "        #print(\"self.attn_combine size: \", output.size())\n",
    "        output = attn_applied \n",
    "\n",
    "        output = F.relu(output)\n",
    "        #print(\"decoder : output de l'attention size -- a l entre du gru : \",output.size())\n",
    "        #print(\"decoder : hidden size -- a l entre du gru : \",hidden.size())\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size*2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "a5595f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# sans attention\\nclass DecoderRNN(nn.Module):\\n    def __init__(self, hidden_size, output_size):\\n        # output_size : taille du vocabulaire anglais\\n        super(DecoderRNN, self).__init__()\\n        self.hidden_size = hidden_size\\n\\n        self.embedding = nn.Embedding(output_size, hidden_size)\\n        # à l entrée du décodeur on a 2*¨hidden_size pour les memoire forward et backward + embidding_size = hidden_size : taille embedding du dernier output predit\\n        self.gru = nn.GRU(3*hidden_size, hidden_size)\\n        self.out = nn.Linear(hidden_size, output_size)\\n        self.softmax = nn.LogSoftmax(dim=1)\\n\\n    def forward(self, input, hidden):\\n        \\n        output = self.embedding(input).view(1, 1, -1)\\n        output = F.relu(output)\\n        output, hidden = self.gru(output, hidden)\\n        output = self.softmax(self.out(output[0]))\\n        return output, hidden\\n\\n    def initHidden(self):\\n        return torch.zeros(1, 1, self.hidden_size, device=device)\\n'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# sans attention\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        # output_size : taille du vocabulaire anglais\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # à l entrée du décodeur on a 2*¨hidden_size pour les memoire forward et backward + embidding_size = hidden_size : taille embedding du dernier output predit\n",
    "        self.gru = nn.GRU(3*hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "f85be0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "9a986702",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei])\n",
    "        #print(\"input_tensor[ei] size : \",input_tensor[ei].size())\n",
    "        #print(\"encoder_outputs[ei] size : \",encoder_outputs[ei].size())\n",
    "        #print(\" encoder_output[0, 0] size : \", encoder_output[0, 0].size())\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "0e46551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7db87d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "99940239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "1eedb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            \n",
    "            #encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden, encoder.hidden_size)\n",
    "            #encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei])\n",
    "            #print(\"input_tensor[ei] size : \",input_tensor[ei].size())\n",
    "            #print(\"encoder_outputs[ei] size : \",encoder_outputs[ei].size())\n",
    "            #print(\" encoder_output[0, 0] size : \", encoder_output[0, 0].size())\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "6afbbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "dba6a161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    torch.device('cuda')\n",
    "else :   \n",
    "    torch_device('cpu')\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "#encoder1 = EncoderRNN(input_dim = input_lang.n_words,emb_dim =256,enc_hid_dim = 1000, dec_hid_dim = 1000, dropout = 0.6) \n",
    "encoder1 = EncoderRNN(input_size = input_lang.n_words, hidden_size = hidden_size)\n",
    "#trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "6ae65ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du modèle\n",
    "#torch.save(encoder1,\"encoder1_bi.pt\")\n",
    "#torch.save(attn_decoder1,\"attn_decoder1_bi.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1c2514a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1_loaded = torch.load(\"encoder1_bi.pt\")\n",
    "attn_decoder1_loaded = torch.load(\"attn_decoder1_bi.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "f7941f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il est trop stupide pour craindre le danger .\n",
      "= he is too dumb to fear danger .\n",
      "< he s too stupid to fear danger . <EOS>\n",
      "\n",
      "> vous etes garee en double file .\n",
      "= you re double parked .\n",
      "< you re very parked . <EOS>\n",
      "\n",
      "> je suis le chef de cette equipe .\n",
      "= i am the leader of this team .\n",
      "< i m your of of this team . <EOS>\n",
      "\n",
      "> je manque d argent .\n",
      "= i am short of money .\n",
      "< i m out of money . <EOS>\n",
      "\n",
      "> elle est hors de danger .\n",
      "= she is out of danger .\n",
      "< she is ashamed of danger . <EOS>\n",
      "\n",
      "> je ne suis pas patiente .\n",
      "= i m not patient .\n",
      "< i m not patient . <EOS>\n",
      "\n",
      "> je rencontre quelqu un pour diner .\n",
      "= i m meeting someone for dinner .\n",
      "< i m going someone for dinner . <EOS>\n",
      "\n",
      "> vous etes un petit menteur .\n",
      "= you re a little liar .\n",
      "< you re a little liar . <EOS>\n",
      "\n",
      "> il te regarde .\n",
      "= he s looking at you .\n",
      "< he s a . <EOS>\n",
      "\n",
      "> je ne vais pas livrer de noms .\n",
      "= i m not going to name names .\n",
      "< i m not of of name . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1_loaded, attn_decoder1_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e748903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9629706a00>"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4edf7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she s five years younger than me . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she s too short . <EOS>\n",
      "input = je ne crains pas de mourir .\n",
      "output = i m not afraid to die . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a talented young man . <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/bdcgs2110sxb3y211lr1nqgr0000gn/T/ipykernel_90679/744067545.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/fp/bdcgs2110sxb3y211lr1nqgr0000gn/T/ipykernel_90679/744067545.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/fp/bdcgs2110sxb3y211lr1nqgr0000gn/T/ipykernel_90679/744067545.py:17: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b1608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
